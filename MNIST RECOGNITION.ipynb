{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Logiciel\\Progra\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Logiciel\\Progra\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Logiciel\\Progra\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Logiciel\\Progra\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Logiciel\\Progra\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Logiciel\\Progra\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Data Vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To handke the data - utils - \n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model construction\n",
    "# from keras.datasets import mnist # Data set\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator # Create more images using the dataset\n",
    "\n",
    "# Variable\n",
    "train = \"./data/train.csv\"\n",
    "test = \"./data/test.csv\"\n",
    "submission = \"./data/sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img, format) :\n",
    "    if (format==\"784\") :\n",
    "        img = img.reshape(28,28)\n",
    "    else :\n",
    "        pass\n",
    "    plt.imshow(img, cmap='Greys_r')\n",
    "    plt.title(\"My Image\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_convolutionnal_model(batch_size, input_shape, num_classes) :\n",
    "    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (4, 4), input_shape=input_shape, activation='relu'))\n",
    "    model.add(Conv2D(32, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))  \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train)\n",
    "df_test = pd.read_csv(test)\n",
    "df_submission = pd.read_csv(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape X_train : (42000, 784).\n",
      "Final Shape X_train : (42000, 28, 28, 1).\n"
     ]
    }
   ],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "y_train = df_train.label\n",
    "X_train = df_train.drop(\"label\", axis=1)\n",
    "n_rows = int(np.sqrt(X_train.shape[1]))\n",
    "n_columns = int(np.sqrt(X_train.shape[1]))\n",
    "n_items_train = X_train.shape[0]\n",
    "n_pixels = n_rows * n_columns\n",
    "input_shape = (n_rows, n_columns, 1)\n",
    "print(\"Initial Shape X_train : {}.\".format(X_train.shape))\n",
    "X_train = X_train.values.reshape(n_items_train, n_rows, n_columns, 1).astype('float32')\n",
    "X_train = X_train/255\n",
    "print(\"Final Shape X_train : {}.\".format(X_train.shape))\n",
    "# showImage(X_train[0], \"784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Count of labels in the train set.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "plt.subplot(121)\n",
    "sns.countplot(x=y_train).set_title(\"Count of labels in the train set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of y_train : (42000,)\n",
      "There are 10 unique labels.\n",
      "Final shape of y_train : (42000,10)\n"
     ]
    }
   ],
   "source": [
    "y_train_backup = y_train # use to modelize\n",
    "print(\"Initial shape of y_train : ({},)\".format(y_train.shape[0]))\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "num_class = len(y_train[0])\n",
    "print(\"There are {} unique labels.\".format(num_class))\n",
    "print(\"Final shape of y_train : ({},{})\".format(y_train.shape[0],y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 32)        16416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               147712    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 254,282\n",
      "Trainable params: 254,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, my_optimizer = get_convolutionnal_model(len(X_train), input_shape, num_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I increase the amount of data to reach a better score. \n",
    "#datagen = ImageDataGenerator(\n",
    "#    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "#    featurewise_std_normalization=False, # set each sample mean to 0\n",
    "#    rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#    width_shift_range=0.2, # randomly shift images horizontally (fraction of total width)\n",
    "#    height_shift_range=0.2,\n",
    "#    horizontal_flip=True) # randomly flip images - horizontaly\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 202s 178ms/step - loss: 0.1112 - acc: 0.9673 - val_loss: 0.0821 - val_acc: 0.9778\n",
      "Epoch 2/10\n",
      "  93/1134 [=>............................] - ETA: 2:52 - loss: 0.0911 - acc: 0.9706"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42) \n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, test_size=0.5, random_state=42) \n",
    "old = time.time()\n",
    "# y_model = model.fit(X_train, y_train, epochs=5, batch_size=5, verbose=1, validation_split=0.1, callbacks=[history]) # First version \n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=30), epochs=10, verbose=1, validation_data=datagen.flow(X_test, y_test), callbacks=[learning_rate_reduction])\n",
    "print(\"It takes {} minutes to train the model.\".format((time.time() - old)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_eval, y_eval)\n",
    "print(\"Loss : \",int(scores[0]*100),\"% / Accuracy : \",int(scores[1]*100),\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss ')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial shape of the test set : {}\".format(df_test.shape))\n",
    "df_test = df_test.values.reshape(df_test.shape[0], n_rows, n_columns, 1).astype('float32')\n",
    "df_test = df_test/255\n",
    "print(\"Final shape of the test set : {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(df_test) :\n",
    "    data_to_predict = item.reshape(1, n_rows, n_columns, 1)\n",
    "    prediction = model.predict(data_to_predict)\n",
    "    p = np.where(prediction[0]==max(prediction[0]))[0][0]\n",
    "    df_submission.loc[df_submission.index[index], \"Label\"] = int(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 5))\n",
    "plt.subplot(121)\n",
    "ax = sns.kdeplot(y_train_backup, shade=True)\n",
    "ax = sns.kdeplot(df_submission.Label, shade=True)\n",
    "ax.set_title(\"Count of the labels\")\n",
    "ax.legend([\"Train set\", \"My predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(submission, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file_based_on_prediction(result, source_file_path=\"data/sample_submission.csv\"):\n",
    "    df = pd.read_csv(\n",
    "        filepath_or_buffer=source_file_path,\n",
    "        sep=\",\",\n",
    "    ).set_index(\"PassengerId\")\n",
    "    print(f\"Entry: {df.shape}.\")\n",
    "    merge_df = pd.merge(\n",
    "        left=df,\n",
    "        right=result,\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    print(f\"Output: {merge_df.shape}.\")\n",
    "    if df.shape[0] != merge_df.shape[0]:\n",
    "        raise ValueError(f\"Should be same size.\")\n",
    "    merge_df = merge_df[[\"Transported_x\", \"Transported_y\"]]\n",
    "    merge_df = merge_df.reset_index().rename(columns={\"Transported_y\": \"Transported\"}).drop(columns=[\"Transported_x\"])\n",
    "    merge_df.to_csv(\"data/my_submission.csv\", sep=\",\", index=False)\n",
    "    \n",
    "def generate_random_submission(source_file_path=\"data/sample_submission.csv\"):\n",
    "    df = pd.read_csv(\n",
    "        filepath_or_buffer=source_file_path,\n",
    "        sep=\",\",\n",
    "    )\n",
    "    df[\"Label\"] = df[\"Label\"].apply(lambda x: random.choice(list(range(10))))\n",
    "    print(f\"File data/my_submission.csv successfully generated.\\n\")\n",
    "    df.to_csv(\"data/my_submission.csv\", sep=\",\", index=False)\n",
    "    \n",
    "def submit_submission(submission_file=\"data/sample_submission.csv\"):\n",
    "    with open(\"kaggle.json\") as credential:\n",
    "        json_credential = json.loads(credential.read())\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = json_credential[\"username\"]\n",
    "        os.environ[\"KAGGLE_KEY\"] = json_credential[\"key\"]\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            \"kaggle\",\n",
    "            \"competitions\",\n",
    "            \"submit\",\n",
    "            \"digit-recognizer\",\n",
    "            \"-f\",\n",
    "            submission_file,\n",
    "            \"-m\",\n",
    "            f\"{dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}: New submission\",\n",
    "        ]\n",
    "    ).decode(\"utf-8\")\n",
    "    print(result)\n",
    "\n",
    "def get_latest_score(team_id=\"10059555\"):\n",
    "    with open(\"kaggle.json\") as credential:\n",
    "        json_credential = json.loads(credential.read())\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = json_credential[\"username\"]\n",
    "        os.environ[\"KAGGLE_KEY\"] = json_credential[\"key\"]\n",
    "        os.environ[\"KAGGLE_TEAM_ID\"] = team_id\n",
    "    result = subprocess.check_output([\"kaggle\", \"competitions\", \"submissions\", \"digit-recognizer\"]).decode(\"utf-8\")\n",
    "    print(result)\n",
    "\n",
    "generate_random_submission(to_predict)\n",
    "submit_submission()\n",
    "get_latest_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
